{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics in Context | A Proof of Concept\n",
    "\n",
    "### Describing Citation Data with [Frictionless](https://frictionlessdata.io/)\n",
    "\n",
    "*Asura Enkhbayar, 04.02.2021*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents a proof of concept for a standardized approach to citation data and, more broadly, scholarly metrics. To do so, we will take a bibliometric dataset consisting of four spreadsheets and build a Frictionless [Data Package](https://specs.frictionlessdata.io/data-package/) using a systematic approach to describe each tables provenance. I will first introduce the dataset at hand and provide an quick overview and situate it in the context of traditional bibliometric work. Then, I will step-by-step introduce a new conceptual framework for scholarly metrics and gradually incorporate the dataset into the final data package. Finally, a few concluding remarks and a brief discussion of the potential and limitations of this approach.\n",
    "\n",
    "*Note: For a broader overview of the project please refer to the [README](https://github.com/Bubblbu/metrics-in-context) in the project repository.*\n",
    "\n",
    "<img style=\"float: center;\" width=25%, src=\"../../materials/assets/fosdem2021.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Let's quickly import a few libraries and functions and setup our folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "from frictionless import describe_schema, Resource, Package\n",
    "\n",
    "# Directories\n",
    "input_files = Path(\"./input_files\")\n",
    "schemas = Path(\"./schemas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this particular notebook, I will not go into the nitty gritty details of this dataset. Of course, providing that kind of information would be part of the aims of developing the Frictionless Data Package for scholarly metrics as these details make up provenance information. For now, I will simply describe the spreadsheets at hand and provide some  cursory descriptions of its origins.\n",
    "\n",
    "The dataset we are working with consists of four spreadsheets that were created based on data provided by [Scite.ai](https://scite.ai/). The particular sample was created by querying for recent articles in Pubmed on Amyotrophic lateral sclerosis (ALS). Scite is one of the newer data sources that not only provide the classic citation link between two documents, but attempt to extract what has been established as citation contexts. While the former can be understood as the datafication of bibliographies and reference lists, context-aware citations trace each individual in-text mention of articles.\n",
    "\n",
    "The four CSVs are:\n",
    "\n",
    "- `contexts.csv`: Article metadata for each DOI.\n",
    "- `traces.csv`: The individual traced citations between documents and context information such as a text snippet or the mentioning section.\n",
    "- `citations.csv`: This spreadsheet contains metrics for every individual citation link derived from its source article such as the total number of outgoing references.\n",
    "- `articles.csv`: A table with article-level metrics derived from the aforementioned traces.\n",
    "\n",
    "Very often, bibliometric researchers and practictioners will only get to see the final article-level metrics, i.e., the citation counts for DOIs. In the next sections, we will now gradually go through these spreadsheets and describe how citation counts become what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Conceptual Framework for Scholarly Metrics\n",
    "\n",
    "Here, I want to attempt to briefly introduce the conceptual framework used to systematize scholarly metrics. This framework is part of a broader doctoral research project and is built around the philosophical shift from object-centrism to process-centrism. This shift from representation towards performance can also be expressed for scholarly metrics by emphasising the processes and practices that lead to outputs and citation counts. But how do these processes look like and how can we start to systematically describe them?\n",
    "\n",
    "The usual story goes something like this: A *citation* links two scholarly texts expressed through an in-text mention and a bibliographic reference. This state is then captured by a *citation link* in their databases. This data then enables the creation of *citation metrics*. I would like to retell this story equipped with a new vocabulary for provenance and while paying attention to each step in the individuation of the citation count.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Citational Event\n",
    "\n",
    "> A *citation* links two *scholarly texts* expressed through an in-text mention and a bibliographic reference.\n",
    "\n",
    "Firstly, I propose to question the idea of the citation as one consistent concept itself. It is typically understood as a directional binary property between two peer-reviewed research articles. However, more and more citation databases are using text-processing methods to extract the individual in-text mentions with their contexts and furthermore the types of documents hosting citations is changing (e.g., datasets, software, mentions in social media). To accomodate for these changes, I suggest to think in terms of *citational events* and their *contexts*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical citation is a statement in a peer-reviewed scholarly article referencing another piece of scholarly writing. Some of the new social (and technical) challenges around citations stem from changing citational practices such as the citing of preprints or datasets. So far, these changes have been pragmatically addressed by introduction of norms and dedicated infrastructure (e.g., the push for DOIs for datasets and iniatives that track their usage) but we are lacking the conceptual language to capture all these forms of citations.\n",
    "\n",
    "To avoid falling into the trap of never-ending definitions, I propose to re-conceptualize the citation as an interdiscursive event (Nakassis, 2013) which links two discursive acts. For the present purpose it will suffice to understand *discursive acts* as some form of written or spoken statement. Modality, syntax, and even semantics become part of the wider context of that particular citational event. I've talked enough about things that bald French men usually talk about, thus, without further ado, let's dive into implementing said citational event:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "type: citational\n",
    "description: A textual reference from one scholarly document to another scholarly document.\n",
    "source_event:\n",
    "  activity: scholarly writing\n",
    "target_event:\n",
    "  activity: scholarly writing\n",
    "```\n",
    "\n",
    "Scite captures *citational* events. Other services also capture events which are not citational such as views, downloads, or bookmarks. Throughout this document, technical objects will always be accompanied with free-text descriptions. Finally, we also attempt to describe the source and target events individually. In our case, both the citing as well as the cited events are caused by scholarly writing. Altmetrics would consider source events caused by social media activities referencing scholarly texts.\n",
    "\n",
    "*Note: This might seem like a very lean definition of the fundamental entity that is being captured. This is on purpose as we will continue to explore the complexity through the additional processes of becoming the final metric.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contexts**\n",
    "\n",
    "These citational events do not occur in a vacuum. As already indicated earlier, they typically happen in contexts which are those things that we usually pay attention to most. The research articles, conference papers, literature reviews, white papers, preprints, and other formats that nowadays host citations of all kinds are the typical unit of analysis when it comes to scholarly metrics. However, with this small committment to the event as the core of this framework, I am hoping to shift attention to the processes and practices leading to citations rather than their manifested forms. Still, we obviously still need to talk and specify these concrete outputs that we love and hate so much. The following yaml excerpt is an example for a list of possible contexts for Scite:\n",
    "\n",
    "```yaml\n",
    "- type: peer-reviewed articles\n",
    "  coverage:\n",
    "    - publishers sharing fulltexts with Scite\n",
    "    - OA articles accessed through Unpaywall\n",
    "    - Pubmed Open Access Subset\n",
    "  identified_by:\n",
    "    - DOI\n",
    "- type: preprints\n",
    "  coverage:\n",
    "    - bioRxiv\n",
    "    - medRxiv\n",
    "  identified_by:\n",
    "    - DOI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tracing of Events and Contexts\n",
    "\n",
    "> This state is then captured by a *citation link* in their databases.\n",
    "\n",
    "How are events and their contexts turned into traces?\n",
    "\n",
    "**Traces**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "event: schemas/event.yaml\n",
    "tracing:\n",
    "  source:\n",
    "\n",
    "  target:\n",
    "    contexts:\n",
    "      - type: peer-reviewed articles\n",
    "        coverage:\n",
    "          - publishers sharing fulltexts with Scite\n",
    "          - OA articles accessed through Unpaywall\n",
    "          - Pubmed Open Access Subset\n",
    "        identified_by:\n",
    "          - DOI\n",
    "      - type: preprints\n",
    "        coverage:\n",
    "          - bioRxiv\n",
    "          - medRxiv\n",
    "        identified_by:\n",
    "          - DOI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns and Metrics\n",
    "\n",
    "> This data then enables the creation of *citation metrics*.\n",
    "\n",
    "\n",
    "\n",
    "**Patterns**\n",
    "\n",
    "All metrics are patterns, but not all patterns are metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citation level patterns\n",
    "\n",
    "This table contains citation patterns aggregated of individual citations.\n",
    "\n",
    "Each table will thus contain:\n",
    "\n",
    "- A unique ID\n",
    "- A source DOI for the citing article\n",
    "- A target DOI for the cited article\n",
    "- One or more patterns\n",
    "    - Each pattern also contain the form of aggregation and input traces/patterns\n",
    "        - Optional for each input trace/pattern: a data resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'source', 'type': 'string'},\n",
       " {'name': 'target', 'type': 'string'},\n",
       " {'name': 'total_source_mentions', 'type': 'integer'},\n",
       " {'name': 'total_source_refs', 'type': 'integer'},\n",
       " {'name': 'mentions', 'type': 'integer'},\n",
       " {'name': 'norm_refs', 'type': 'number'},\n",
       " {'name': 'norm_mentions', 'type': 'number'},\n",
       " {'name': 'mentions_per_ref', 'type': 'number'},\n",
       " {'name': 'wf1', 'type': 'number'},\n",
       " {'name': 'wf2', 'type': 'number'},\n",
       " {'name': 'wf3', 'type': 'number'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = data_dir / \"citation_patterns.csv\"\n",
    "cit_patterns = pd.read_csv(f)\n",
    "cp_schema = describe_schema(f)\n",
    "cp_schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'name': 'source', 'type': 'string'},\n",
       "  {'name': 'target', 'type': 'string'},\n",
       "  {'name': 'total_source_mentions', 'type': 'integer'},\n",
       "  {'name': 'total_source_refs', 'type': 'integer'},\n",
       "  {'name': 'mentions', 'type': 'integer'},\n",
       "  {'name': 'norm_refs', 'type': 'number'},\n",
       "  {'name': 'norm_mentions', 'type': 'number'},\n",
       "  {'name': 'mentions_per_ref', 'type': 'number'},\n",
       "  {'name': 'wf1', 'type': 'number'},\n",
       "  {'name': 'wf2', 'type': 'number'},\n",
       "  {'name': 'wf3', 'type': 'number'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_schema.name = \"citation_patterns\"\n",
    "cp_schema.description = \n",
    "\n",
    "ap_schema.primary_key = \"doi\"\n",
    "ap_schema.get_field(\"doi\").title = \"DOI of citing article\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article level patterns\n",
    "\n",
    "This table contains citation patterns aggregated on the article level.\n",
    "\n",
    "Each table will thus contain:\n",
    "\n",
    "- A unique DOI\n",
    "- One or more patterns for each DOI\n",
    "    - Each pattern also contain the form of aggregation and input traces/patterns\n",
    "        - Optional for each input trace/pattern: a data resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"article_patterns.csv\"\n",
    "article_patterns = pd.read_csv(f)\n",
    "ap_schema = describe_schema(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-41b5306200e4>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-41b5306200e4>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    \"type\": \"aggregation\",\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Set primary key\n",
    "ap_schema.primary_key = \"doi\"\n",
    "ap_schema.get_field(\"doi\").title = \"DOI of citing article\"\n",
    "\n",
    "# First pattern: mentions_agg\n",
    "mentions_agg = ap_schema.get_field(\"mentions_agg\")\n",
    "mentions_agg.title = \"Aggregated mentions\"\n",
    "mentions_agg.description = \"Sum of all incoming mentions for this DOI\"\n",
    "mentions_agg.type = \"integer\"\n",
    "mentions_agg.missing_values = [\"\", \"n/a\", \"NaN\"]\n",
    "mentions_agg.mic = {\n",
    "    \"type\": \"pattern\",\n",
    "    \"prov\": {\n",
    "        \"operation\": {\n",
    "            \"description\": \"Aggregation of all citations by DOI\"\n",
    "            \"type\": \"aggregation\",\n",
    "            \"by\": \"doi\",\n",
    "            \"resource\": \"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Second pattern: refs_agg\n",
    "refs_agg = ap_schema.get_field(\"refs_agg\")\n",
    "refs_agg.title = \"Aggregated references\"\n",
    "refs_agg.description = \"Sum of all incoming references for this DOI\"\n",
    "refs_agg.type = \"integer\"\n",
    "refs_agg.missing_values = [\"\", \"n/a\", \"NaN\"]\n",
    "refs_agg.mic = {\n",
    "    \"type\": \"pattern\",\n",
    "    \"prov\": {\n",
    "        \"operation\": {\n",
    "            \"type\": \"aggregation\",\n",
    "            \"by\": \"doi\",\n",
    "            \"input\": \"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add third pattern which is an average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource specs\n",
    "resource_desc = {\n",
    "    \"profile\": \"pattern\",\n",
    "    \"name\": \"Article-level metrics\",\n",
    "    \"data\": data_dir / \"article_patterns.csv\",\n",
    "    \"schema\": ap_schema\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Benefits:\n",
    "\n",
    "- Also provides a logical structure for bibliometrics datasets\n",
    "- By splitting data resources and schemas it is possible to discuss provenance information without having actual data of any prior stages and processes\n",
    "- Frictionless enables the addition of logic and function to the data packages which opens door for extensions:\n",
    "    - Automatically retrieve metadata and citations from open services (Crossref/COCI) including their provenance schemas of course\n",
    "    - Compare metrics in a dataset and automatically point out incommensurable fields\n",
    "    - Automatically emphasize black-boxes in the data processing pipelines\n",
    "    - Create visualizations of these provenance pipelines\n",
    "\n",
    "Drawbacks:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Nakassis, C. V. (2013). Citation and Citationality. Signs and Society, 1(1), 51â€“77. https://doi.org/10.1086/670165"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics-in-context",
   "language": "python",
   "name": "metrics-in-context"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
