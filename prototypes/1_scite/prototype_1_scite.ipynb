{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics in Context | A Proof of Concept\n",
    "\n",
    "### Describing Citation Data with [Frictionless](https://frictionlessdata.io/)\n",
    "\n",
    "*Asura Enkhbayar, 04.02.2021*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents a proof of concept for a standardized approach to providing provenance information for citation data and, more broadly, scholarly metrics. To do so, we will take a bibliometric dataset consisting of four spreadsheets and build a Frictionless [Data Package](https://specs.frictionlessdata.io/data-package/) while describing the internal structure of the spreadsheets as well as their provenance. To do so, I will step-by-step introduce a new conceptual framework for scholarly metrics and gradually incorporate the dataset into the final data package.\n",
    "\n",
    "*Note: For a broader overview of the project please refer to the [README](https://github.com/Bubblbu/metrics-in-context) in the project repository.*\n",
    "\n",
    "<img style=\"float: center;\" width=25%, src=\"../../materials/assets/fosdem2021.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly import a few libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "from frictionless import describe_resource, Schema, Package\n",
    "\n",
    "# directories\n",
    "input_files = Path(\"./input_files\")\n",
    "schemas = Path(\"./schemas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "For the purpose of this particular notebook, I will not go into the nitty gritty details of this particular dataset. Of course, doing exactly that is one of the goals of creating a the Frictionless Data Package for scholarly metrics. For now, I will simply provide some high-level explanations for the dataset and a cursory description for each spreadsheet.\n",
    "\n",
    "The dataset we are working with consists is provided by [Scite.ai](https://scite.ai/). The particular sample was created by querying Pubmed for articles on Amyotrophic lateral sclerosis (ALS). Scite is one of the newer data sources that not only provide the classic citation link between two documents (\"A cites B\"), but attempt to extract what has been established as citation contexts (\"A mentions B 3 times in the introduction\"). Using the data they provide, I have derived four CSV files:\n",
    "\n",
    "- `article_metadata.csv`: Article metadata for each DOI like title, authors, journal, etc.\n",
    "- `mentions.csv`: The individual traced citations between documents and context information such as a text snippet or the mentioning section.\n",
    "- `citation_metrics.csv`: This spreadsheet contains metrics for every individual citation link derived from its source article such as the total number of outgoing references.\n",
    "- `article_metrics.csv`: A table with article-level metrics derived from the aforementioned traces.\n",
    "\n",
    "In bibliometrics and research assessment we often focus on the last file, the citation counts and related metrics for the individual articles. In the rest of this document, we will work our way up from the actual citation in a document to the final citation count and attempt to model and capture each step on our way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling A Metrics Data Package\n",
    "\n",
    "The conceptual framework introduced throughout the next sections is part of a broader doctoral research project (mine *cough*) and is built around the shift from representation towards performance. This shift, also conceivable as the move from object-centrism to process-centrism, also impinges on scholarly metrics in the form of attention towards processes and practices rather than outputs and metrics. But how do these processes look like in detail and how can we start to systematically describe them?\n",
    "\n",
    "The usual story goes something like this: \n",
    "\n",
    "> A *citation* links two scholarly texts expressed through an in-text mention and a bibliographic reference.\n",
    "> This state is then captured by a *citation link* in their databases.\n",
    "> This data then enables the creation of *citation metrics*.\n",
    "\n",
    "I would like to retell this story while introducing a new framework and vocabulary for metrics provenance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Citational Event\n",
    "\n",
    "> A *citation* links two *scholarly texts* expressed through an in-text mention and a bibliographic reference.\n",
    "\n",
    "Let's go to the very beginning of any citation count, h-index, or JIF. The citation itself is typically understood as a directional binary relation between two peer-reviewed research articles. However, not only are the kinds of documents and outputs changing (datasets, software, social media) but indexing technology is also improving and providing more than a simple binary state as the dataset we are using shows. To accomodate for these changes, I suggest to think of *citational events* and their *contexts* as our basic analytic unit. One important difference that this model introduces to the traditional conceptualization of the citation is that we never observe a direct relation between documents, dataset, or any output. These links are always mediated by citational events.\n",
    "\n",
    "![citational_event](../../materials/assets/citational_event.png)\n",
    "\n",
    "To avoid falling into the trap of never-ending re-definitions of citable items (e.g. articles, preprints, datasets, software, ...) I propose to re-conceptualize the citation as any form of written or spoken statement that references another one. This occurance of a discursive act linking to another one can then be understood as an interdiscursive event (Nakassis, 2013). The material manifestation of those acts (written text, published datasets, software) are the contexts of those particular events. I've talked enough about things that bald French men usually talk about, thus, without further ado, let's dive into implementing said citational event:\n",
    "\n",
    "```yaml\n",
    "type: citational\n",
    "description: A textual reference from one scholarly document to another scholarly document.\n",
    "source_event:\n",
    "  activity: scholarly writing\n",
    "target_event:\n",
    "  activity: scholarly writing\n",
    "```\n",
    "\n",
    "This YAML object is a model of the event that Scite captures. Moving forward, we will construct multiple of these provenance schemas to describe the processes of scholarly metrics. Here, `type` denotes that Scite captures *citational* events (other events which are not citational are views, downloads, or bookmarks). Both `source_event` and and `target_event` are specified by the processes that lead to their creations. In our case, both the citing as well as the cited events are caused by scholarly writing. This specification does *not* say anything about the kinds of outputs that are considered. For these, we can now move on to...\n",
    "\n",
    "*Note: This might seem like a very lean definition of the fundamental entity that is being captured. This is on purpose as we will continue to explore the complexity through the additional processes of becoming the final metric.*\n",
    "\n",
    "*Another note: The event provenance schema models the actual citational event, i.e., the citations happening in scholarly articles. Thus, there is no data representation (a CSV file) that captures these *act of citing*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexts\n",
    "\n",
    "Events do not occur in a vacuum. Citational events happen in their contexts which we might be more familiar with as research articles, preprints, tweets, news articles, datasets, and many more things. These contexts majorly impact how the final scholarly metrics look: Web of Science indexes a particular subset of the scientific literature, Google Scholar indexes all the pages that they are aware of, and Scite.ai can work the documents that they access via publisher agreements or because of open licenses. In the following provenance schema, we will attempt capture these fundamnetal differences:\n",
    "\n",
    "*Note: This is a quite rudimentary example for the dataset at hand. It is mostly speculative (input highly welcome, Scite.ai folks!)*\n",
    "\n",
    "```yaml\n",
    "contexts:\n",
    "    - type: peer-reviewed articles\n",
    "      coverage:\n",
    "        - publishers sharing fulltexts with Scite\n",
    "        - Pubmed Open Access Subset\n",
    "        - OA articles accessed through Unpaywall\n",
    "      identified_by:\n",
    "        - DOI\n",
    "    - type: preprints\n",
    "      coverage:\n",
    "        - bioRxiv\n",
    "        - medRxiv\n",
    "      identified_by:\n",
    "        - DOI\n",
    "```\n",
    "\n",
    "As we can see, a data source can contain multiple types of contexts. E.g., preprints and peer-reviewed articles which might be similar documents but run on very different social and technical infrastructures. More importantly, as we can see in this example, it is encouraged to be as precise and extensive as possible in terms of the concrete coverage of context types. By doing so, it also becomes possible to imagine the value of these provenance schemas as the comparison of context schemas from different data sources could be easily achieved with computational, visual, as well as purely textual approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding our first Frictionless Data Resource**\n",
    "\n",
    "Now that we have defined the events and contexts in Scite.ai, we can start loading the first CSV: `input_files/article_metadata.csv` which is pretty straightforward article metadata. Let's see how we can combine real data and our provenance schemas using Frictionless. Frictionless provides the high-level function `describe_resource` which sets up a `Resource` object in addition to doing some initial processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite_contexts = describe_resource(\"input_files/article_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps, we will set some basic properties to describe the context resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite_contexts.name = \"scite-contexts\"\n",
    "scite_contexts.profile = \"mic-contexts\" # this profile does not exist yet\n",
    "scite_contexts.description = \"Context metadata from Scite.ai | articles identified by DOI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, Frictionless uses [Table Schemas](https://specs.frictionlessdata.io/table-schema/) to describe the structure of tabular data. In this case, an initial schema has already been extracted and setup by `describe_resource` which we now can manually expand. For instance, the spreadsheet contains one article per row identified by the `doi` column and the `title`, `authors`, `journal`, `type`, and `year`. Accordingly, we should set \"doi\" as the primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite_contexts.schema.primary_key = \"doi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add a new property `prov` which we will populate with the previously created schema for Scite contexts. To do so, we will use the `Schema` class and directly load the YAML file from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite_contexts['prov'] = Schema(\"schemas/contexts.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our new data resource containing contexts looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compression': 'no',\n",
      " 'compressionPath': '',\n",
      " 'control': {'newline': ''},\n",
      " 'description': 'Context metadata from Scite.ai | articles identified by DOI',\n",
      " 'dialect': {'quoteChar': '\"'},\n",
      " 'encoding': 'utf-8',\n",
      " 'format': 'csv',\n",
      " 'hashing': 'md5',\n",
      " 'name': 'scite-contexts',\n",
      " 'path': 'input_files/article_metadata.csv',\n",
      " 'profile': 'mic-contexts',\n",
      " 'prov': {'contexts': [{'coverage': ['publishers sharing fulltexts with Scite',\n",
      "                                     'Pubmed Open Access Subset',\n",
      "                                     'OA articles accessed through Unpaywall'],\n",
      "                        'identified_by': ['DOI'],\n",
      "                        'type': 'peer-reviewed articles'},\n",
      "                       {'coverage': ['bioRxiv', 'medRxiv'],\n",
      "                        'identified_by': ['DOI'],\n",
      "                        'type': 'preprints'}]},\n",
      " 'query': {},\n",
      " 'schema': {'fields': [{'name': 'doi', 'type': 'string'},\n",
      "                       {'name': 'title', 'type': 'string'},\n",
      "                       {'name': 'authors', 'type': 'string'},\n",
      "                       {'name': 'journal', 'type': 'string'},\n",
      "                       {'name': 'type', 'type': 'string'},\n",
      "                       {'name': 'year', 'type': 'number'}],\n",
      "            'primaryKey': 'doi'},\n",
      " 'scheme': 'file',\n",
      " 'stats': {'bytes': 52336,\n",
      "           'fields': 6,\n",
      "           'hash': 'ecbfed390cb29796c145c6c857c92ee3',\n",
      "           'rows': 100}}\n"
     ]
    }
   ],
   "source": [
    "pprint(scite_contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might not look like much so far, but we have successfully loaded a spreadsheet containing article metadata into a data structure which provides mechanisms to simultaneously account for:\n",
    "\n",
    "1. The internal structure and logics of the raw data using `schema`\n",
    "2. The kind of contexts that are captured using the new `prov` property, i.e., **we are doing provenance!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tracing Events and Contexts\n",
    "\n",
    "> This state is then captured by a *citation link* in their databases.\n",
    "\n",
    "The processes involved in the capturing of citations might be the most overlooked and undertheorized aspect of modern citations. Citation theory, citation-based indicators and metrics, and the responsible use of research metrics are all areas that get their FAIR share of attention. But what about the tracing of citational events and their way into our databases of knowledge?\n",
    "\n",
    "To answer this question, I want to introduce *processes of tracing* which create an imprint or *trace* of a citational event in a database. Citation indexes are the obvious example for institutions that trace citational events by systematically registering citing and cited documents. In the recent years, however, with the rapid growth of citation data providers the landscape of citation tracing methods is also growing and becoming increasingly complex.\n",
    "\n",
    "One of the reasons why processes of tracing haven't been scrutitinized in detail yet might be that most of them are still black boxes. However, we can still attempt to identify these black-boxes and label them as such. This exercises' value becomes especially clear once we start to apply the same vocabulary of tracing processes to newer open data sources such as [OpenCitations](http://opencitations.net/index/coci) which in turn should be transparent. For the current purposes, I will again provide a speculative and quite rudimentary example of a tracing pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "event: schemas/event.yaml\n",
    "contexts: schemas/contexts.yaml\n",
    "tracing:\n",
    "  pipeline:\n",
    "    - citation_extraction: text-processing/ML\n",
    "    - citation_reference_matching: text-processing/ML\n",
    "    - reference_document_matching: ID matching\n",
    "```\n",
    "\n",
    "This basic example of the provenance schemas for Scite traces references the two previously developed models for *events* and *contexts*. This is a mandatory condition for any data resource which contains traces as the kind of events and the concrete manifestation of their contexts are crucial information about the origin of this dataset. Furthermore, this schema should also provide insights about the actual tracing process which will typically be a pipeline of individual steps. In this case, I have only chosen the extraction of citation statements, the matching of in-text mentions with the entries in the bibliography, and the matching of references with other documents in that database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our second Frictionless Data Resource**\n",
    "\n",
    "Once again, we can now use `describe_resource` to load the CSV with the actual in-text mention data from Scite: `input_files/mentions.csv` which contains an individual in-text mention per line identified by an `id`. They also specify the `source` and `target` DOI as well as the name of the `section` the target was mentioned in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite_traces = describe_resource(\"input_files/mentions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will once again set some basic properties like a name, descriptor, and a profile, and a primary key on `id`. However, in addition we can designate both `source` and `target` as foreign keys as the each DOI is also in the contexts resource which contains all metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some general properties\n",
    "scite_traces.name = \"scite-traces\"\n",
    "scite_traces.profile = \"mic-traces\"\n",
    "scite_traces.description = \"Traced citing-cited article pairs for each mention\"\n",
    "\n",
    "# Extend the table schema\n",
    "scite_traces.schema.primary_key = \"id\"\n",
    "scite_traces.schema.foreign_keys.append(\n",
    "    {\"fields\": [\"source\"], \"reference\": {\"resource\": \"scite-contexts\", \"fields\": [\"doi\"]}}\n",
    ")\n",
    "scite_traces.schema.foreign_keys.append(\n",
    "    {\"fields\": [\"target\"], \"reference\": {\"resource\": \"scite-contexts\", \"fields\": [\"doi\"]}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing missing is the provenance information. Just as we did last time, we are going to use the `prov` property to add our experimental trace schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite_traces['prov'] = Schema(\"schemas/traces.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final data resource containing Scite traces looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compression': 'no',\n",
      " 'compressionPath': '',\n",
      " 'control': {'newline': ''},\n",
      " 'description': 'Traced citing-cited article pairs for each mention',\n",
      " 'dialect': {},\n",
      " 'encoding': 'utf-8',\n",
      " 'format': 'csv',\n",
      " 'hashing': 'md5',\n",
      " 'name': 'scite-traces',\n",
      " 'path': 'input_files/mentions.csv',\n",
      " 'profile': 'mic-traces',\n",
      " 'prov': {'contexts': 'schemas/contexts.yaml',\n",
      "          'event': 'schemas/event.yaml',\n",
      "          'tracing': {'pipeline': [{'citation_extraction': 'text-processing/ML'},\n",
      "                                   {'citation_reference_matching': 'text-processing/ML'}]}},\n",
      " 'query': {},\n",
      " 'schema': {'fields': [{'name': 'field1', 'type': 'integer'},\n",
      "                       {'name': 'id', 'type': 'integer'},\n",
      "                       {'name': 'source', 'type': 'string'},\n",
      "                       {'name': 'target', 'type': 'string'},\n",
      "                       {'name': 'section', 'type': 'string'}],\n",
      "            'foreignKeys': [{'fields': ['source'],\n",
      "                             'reference': {'fields': ['doi'],\n",
      "                                           'resource': 'scite-contexts'}},\n",
      "                            {'fields': ['target'],\n",
      "                             'reference': {'fields': ['doi'],\n",
      "                                           'resource': 'scite-contexts'}}],\n",
      "            'primaryKey': 'id'},\n",
      " 'scheme': 'file',\n",
      " 'stats': {'bytes': 5551,\n",
      "           'fields': 5,\n",
      "           'hash': '62d84ee89a9aca9604f03de4941b485a',\n",
      "           'rows': 59}}\n"
     ]
    }
   ],
   "source": [
    "pprint(scite_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time our data resource already contains considerably more complexity:\n",
    "    \n",
    "1. The internal structure of the CSV and its columns is no longer limited to this one resource. We have added foreignKeys which reference rows in the `scite_contexts` resource.\n",
    "2. The provenance information is also relational. Not only have we defined that the kind of captured events (`schemas/events.yaml` which we wrote earlier) but also the contexts in which we are actually looking for these events (`schemas/contexts.yaml`). Finally, we have started to describe parts of the tracing pipeline in very rudimentary terms.\n",
    "\n",
    "**Look mum, more provenance!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Patterns and Metrics I\n",
    "\n",
    "> This data then enables the creation of *citation metrics*.\n",
    "\n",
    "So far, we have modelled the underlying event in Scite, described the kinds of contexts that host these events, and defined how the these events and contexts are transformed into data traces. The last missing step is now to close the gap between these traces and the metrics that we are so familiar with. In the framework that I am presenting, *processes of patterning* take traces (i.e., \"data imprints\" of events) and rearrange them in interesting pattern that are meaningful to us. This means that all the metrics we are familiar with are patterns derived from traces.\n",
    "\n",
    "Dataset containing scholarly metrics can be organized in various ways. Individual tables could be representative for different data sources or different context types. However, commonly scholarly metrics are presented as tidy data, i.e., rows represent individual articles by DOI and columns are the measurements or metrics. Thus, we will now introduce a new option in the provenance schema to be able to describe individual fields in the dataset:\n",
    "\n",
    "```yaml\n",
    "fields:\n",
    "  - mentions:\n",
    "      name: mentions\n",
    "      description: the number of times that the target was mentioned by the source\n",
    "      resources:\n",
    "        - scite_traces\n",
    "  - norm_mentions:\n",
    "      name: norm_mentions\n",
    "      description: number of mentions normalized by total outgoing mentions of the source\n",
    "      resources:\n",
    "        - scite_traces\n",
    "```\n",
    "\n",
    "The CSV we are loading now is `input_files/citation_metrics.csv` which provides metrics for each pair of citing and cited articles. However, in contrast to the traditional citation count which would assign a value of 1 to each unique pair, in this case we are actually counting the number of mentions. In order to achieve that, we obviously require the `scite_traces` resource that we created earlier (which in turn contains the full provenance information up to this point)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The third Frictionless Data Resource**\n",
    "\n",
    "Let's load the respective file for this provenance schema and repeat the previous exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_patterns = describe_resource(\"input_files/citation_metrics.csv\")\n",
    "\n",
    "# Some general properties\n",
    "citation_patterns.name = \"citation-patterns\"\n",
    "citation_patterns.profile = \"mic-patterns\"\n",
    "citation_patterns.description = \"Patterns for unique source and target pairs\"\n",
    "\n",
    "# Extend the table schema\n",
    "citation_patterns.schema.primary_key = \"id\"\n",
    "citation_patterns.schema.foreign_keys.append(\n",
    "    {\"fields\": [\"source\"], \"reference\": {\"resource\": \"scite-contexts\", \"fields\": [\"doi\"]}}\n",
    ")\n",
    "citation_patterns.schema.foreign_keys.append(\n",
    "    {\"fields\": [\"target\"], \"reference\": {\"resource\": \"scite-contexts\", \"fields\": [\"doi\"]}}\n",
    ")\n",
    "\n",
    "# Adding a constraint to the normalized mention which can't be smaller than 0\n",
    "citation_patterns.schema.get_field(\"norm_mentions\").constraints = {\"minimum\": 0}\n",
    "\n",
    "# Add provenance schema\n",
    "citation_patterns['prov'] = Schema(\"schemas/citation_patterns.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first pattern resource then looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'citation-patterns',\n",
       " 'profile': 'mic-patterns',\n",
       " 'path': 'input_files/citation_metrics.csv',\n",
       " 'scheme': 'file',\n",
       " 'format': 'csv',\n",
       " 'hashing': 'md5',\n",
       " 'encoding': 'utf-8',\n",
       " 'compression': 'no',\n",
       " 'compressionPath': '',\n",
       " 'control': {'newline': ''},\n",
       " 'dialect': {},\n",
       " 'query': {},\n",
       " 'schema': {'fields': [{'name': 'id', 'type': 'integer'},\n",
       "   {'name': 'source', 'type': 'string'},\n",
       "   {'name': 'target', 'type': 'string'},\n",
       "   {'name': 'mentions', 'type': 'integer'},\n",
       "   {'name': 'norm_mentions', 'type': 'number', 'constraints': {'minimum': 0}}],\n",
       "  'primaryKey': 'id',\n",
       "  'foreignKeys': [{'fields': ['source'],\n",
       "    'reference': {'resource': 'scite-contexts', 'fields': ['doi']}},\n",
       "   {'fields': ['target'],\n",
       "    'reference': {'resource': 'scite-contexts', 'fields': ['doi']}}]},\n",
       " 'stats': {'hash': 'c55ab9fb2f445aa8893787b03bcb829f',\n",
       "  'bytes': 2330,\n",
       "  'fields': 5,\n",
       "  'rows': 31},\n",
       " 'description': 'Patterns for unique source and target pairs',\n",
       " 'prov': {'fields': [{'mentions': {'name': 'mentions',\n",
       "     'description': 'the number of times that the target was mentioned by the source',\n",
       "     'resources': ['scite_traces']}},\n",
       "   {'norm_mentions': {'name': 'norm_mentions',\n",
       "     'description': 'number of mentions normalized by total outgoing mentions of the source',\n",
       "     'resources': ['scite_traces']}}]}}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have constructed our first data resource that does not directly derive from the captured events as we used the Scite traces as input variables. Once again, we achieve both goals of describing the internal structure of the table at hand while providing its provenence information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Patterns and Metrics II\n",
    "\n",
    "Finally, we are now ready to assemble the final data resource that everyone has been waiting for... Article-level metrics! Everyone wants to know how often their most recent paper has been cited or in this case we could also look at the number of in-text mentions. So, without further ado, I present the final provenance schema for article-level patterns:\n",
    "\n",
    "```yaml\n",
    "fields:\n",
    "  - mentions_agg:\n",
    "      - name: mentions_agg\n",
    "      - description: the total number of mentions aggregated by target articles\n",
    "      - resource:\n",
    "        - citation_patterns\n",
    "  - refs_agg:\n",
    "      - name: refs_agg\n",
    "      - description: the classic citation count. the number of unique citing articles for each cited article\n",
    "      - resource:\n",
    "        - citation_patterns\n",
    "```\n",
    "\n",
    "We are now introducing our final two patterns: `mentions_agg` which is the total number of in-text mentions for each article. In contrast, `refs_agg` is the traditional citation count which is the plain number of articles that mentioned the target one. I want to simply point that the input resource for both these fields are not of the type `mic-traces` as our Scite trace data resource. As mentioned earlier, patterns can take either traces or other patterns as input data in order to produce new patterns. The only important thing for us is to maintain the chain of provenance information.\n",
    "\n",
    "**The fourth and final Frictionless Data Resource**\n",
    "\n",
    "This final resource is pretty much the same as the previous one. One difference being that the primary key of the table is also a foreign key at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compression': 'no',\n",
      " 'compressionPath': '',\n",
      " 'control': {'newline': ''},\n",
      " 'description': 'Patterns for individual articles',\n",
      " 'dialect': {},\n",
      " 'encoding': 'utf-8',\n",
      " 'format': 'csv',\n",
      " 'hashing': 'md5',\n",
      " 'name': 'article-patterns',\n",
      " 'path': 'input_files/article_metrics.csv',\n",
      " 'profile': 'mic-patterns',\n",
      " 'prov': {'fields': [{'mentions_agg': [{'name': 'mentions_agg'},\n",
      "                                       {'description': 'the total number of '\n",
      "                                                       'mentions aggregated by '\n",
      "                                                       'target articles'},\n",
      "                                       {'resource': ['citation_patterns']}]},\n",
      "                     {'refs_agg': [{'name': 'refs_agg'},\n",
      "                                   {'description': 'the classic citation '\n",
      "                                                   'count. the number of '\n",
      "                                                   'unique citing articles for '\n",
      "                                                   'each cited article'},\n",
      "                                   {'resource': ['citation_patterns']}]}]},\n",
      " 'query': {},\n",
      " 'schema': {'fields': [{'name': 'doi', 'type': 'string'},\n",
      "                       {'constraints': {'minimum': 0},\n",
      "                        'name': 'mentions_agg',\n",
      "                        'type': 'integer'},\n",
      "                       {'constraints': {'minimum': 0},\n",
      "                        'name': 'refs_agg',\n",
      "                        'type': 'integer'}],\n",
      "            'primaryKey': 'doi'},\n",
      " 'scheme': 'file',\n",
      " 'stats': {'bytes': 172,\n",
      "           'fields': 3,\n",
      "           'hash': '5369060f124f2bf9881810af42bd167a',\n",
      "           'rows': 5}}\n"
     ]
    }
   ],
   "source": [
    "article_patterns = describe_resource(\"input_files/article_metrics.csv\")\n",
    "\n",
    "# Some general properties\n",
    "article_patterns.name = \"article-patterns\"\n",
    "article_patterns.profile = \"mic-patterns\"\n",
    "article_patterns.description = \"Patterns for individual articles\"\n",
    "\n",
    "# Extend the table schema\n",
    "article_patterns.schema.primary_key = \"doi\"\n",
    "# article_patterns.schema.foreign_keys.append(\n",
    "#     {\"fields\": [\"doi\"], \"reference\": {\"resource\": \"scite-contexts\", \"fields\": [\"doi\"]}}\n",
    "# )\n",
    "\n",
    "# Adding a constraint to the normalized mention which can't be smaller than 0\n",
    "article_patterns.schema.get_field(\"mentions_agg\").constraints = {\"minimum\": 0}\n",
    "article_patterns.schema.get_field(\"refs_agg\").constraints = {\"minimum\": 0}\n",
    "\n",
    "# Add provenance schema\n",
    "article_patterns['prov'] = Schema(\"schemas/article_patterns.yaml\")\n",
    "\n",
    "pprint(article_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done it! We are now proud owners of article-level metrics as a Frictionless data resource **with provenance information attached!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling the Final Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to use the four resources that we created so far and combine them into a *Frictionless Data Packate*. The function call is pretty straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "scite = Package(resources=[scite_contexts, scite_traces, citation_patterns, article_patterns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now both able to look at the data tables in each resource as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mentions_agg</th>\n",
       "      <th>refs_agg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doi</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10.1186/s13023-016-0444-9</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1212/wnl.0000000000004179</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.3892/etm.2018.6726</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.3390/md15040089</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1007/s12035-016-0271-y</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mentions_agg  refs_agg\n",
       "doi                                                 \n",
       "10.1186/s13023-016-0444-9               14         8\n",
       "10.1212/wnl.0000000000004179            15         6\n",
       "10.3892/etm.2018.6726                    2         1\n",
       "10.3390/md15040089                      13         7\n",
       "10.1007/s12035-016-0271-y               15         9"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scite.get_resource(\"article-patterns\").to_pandas().dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While also being able to very quickly produce an overview of the provenance information contained in the data package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Resource: scite-contexts\n",
      "{'contexts': [{'coverage': ['publishers sharing fulltexts with Scite',\n",
      "                            'Pubmed Open Access Subset',\n",
      "                            'OA articles accessed through Unpaywall'],\n",
      "               'identified_by': ['DOI'],\n",
      "               'type': 'peer-reviewed articles'},\n",
      "              {'coverage': ['bioRxiv', 'medRxiv'],\n",
      "               'identified_by': ['DOI'],\n",
      "               'type': 'preprints'}]}\n",
      "\n",
      "=== Data Resource: scite-traces\n",
      "{'contexts': 'schemas/contexts.yaml',\n",
      " 'event': 'schemas/event.yaml',\n",
      " 'tracing': {'pipeline': [{'citation_extraction': 'text-processing/ML'},\n",
      "                          {'citation_reference_matching': 'text-processing/ML'}]}}\n",
      "\n",
      "=== Data Resource: citation-patterns\n",
      "{'fields': [{'mentions': {'description': 'the number of times that the target '\n",
      "                                         'was mentioned by the source',\n",
      "                          'name': 'mentions',\n",
      "                          'resources': ['scite_traces']}},\n",
      "            {'norm_mentions': {'description': 'number of mentions normalized '\n",
      "                                              'by total outgoing mentions of '\n",
      "                                              'the source',\n",
      "                               'name': 'norm_mentions',\n",
      "                               'resources': ['scite_traces']}}]}\n",
      "\n",
      "=== Data Resource: article-patterns\n",
      "{'fields': [{'mentions_agg': [{'name': 'mentions_agg'},\n",
      "                              {'description': 'the total number of mentions '\n",
      "                                              'aggregated by target articles'},\n",
      "                              {'resource': ['citation_patterns']}]},\n",
      "            {'refs_agg': [{'name': 'refs_agg'},\n",
      "                          {'description': 'the classic citation count. the '\n",
      "                                          'number of unique citing articles '\n",
      "                                          'for each cited article'},\n",
      "                          {'resource': ['citation_patterns']}]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in  scite[\"resources\"]:\n",
    "    print(f\"=== Data Resource: {r['name']}\")\n",
    "    pprint(r[\"prov\"])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook presented a proof of concept for the systematic and programmatic description of provenance information for metrics using Frictionless. Especially using the features built into the Frictionless toolkit with data packages, data resources, and table schemas we were able to provide information about the internal logics of the complete dataset. In addition, I introduced the concepts of citational events, contexts, traces, and patterns in order to model the underlying provenance of the same dataset. By extending the individual data resources with a `prov` property, I have attempted to extend the Frictionless toolkit to accomodate for provenance.\n",
    "\n",
    "Some practical benefits of this approach for the research commnunity:\n",
    "\n",
    "- The splitting of provenance information and data tables allows us to model the former (or even require) even if the enduser does not have access to the raw data.\n",
    "- The introduction of contexts, traces, and patterns could contribute to the development of a best-practice for bibliometric research projects and scholarly metrics in general.\n",
    "\n",
    "Benefits for practicioners and society in general:\n",
    "\n",
    "- By creating provenance schemas for individual data sources (and publishing them openly) we create a publicly available, standardardized resource which provides metadata on data sources. Furthermore, we are able to account for black-boxes as we can model the individual processes of metrics independently.\n",
    "\n",
    "Finally, a few potential extensions for a Frictionless Metrics Data Package that might be fun to explore:\n",
    "\n",
    "- Automatically emphasize black-boxes in the data processing pipelines or missing provenance information for patterns/metrics\n",
    "- Compare metrics in a dataset and automatically point out incommensurable fields\n",
    "- Create visualizations of these provenance pipelines\n",
    "- Automatically retrieve metadata and citations from open services (Crossref/COCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Nakassis, C. V. (2013). Citation and Citationality. Signs and Society, 1(1), 51–77. https://doi.org/10.1086/670165"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics-in-context",
   "language": "python",
   "name": "metrics-in-context"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
